# -*- coding: utf-8 -*-
"""qa_bot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hGhGfTdGG4RIcJQkn60HQ_KS3UkczPZy
"""

!pip install langchain openai faiss-cpu pypdf python-dotenv sentence-transformers

!pip install -U langchain-community

from google.colab import files

uploaded = files.upload()
pdf_path = list(uploaded.keys())[0]
print(f"Uploaded file: {pdf_path}")

from langchain_community.document_loaders import PyPDFLoader

# Load PDF file
loader = PyPDFLoader(pdf_path)
docs = loader.load()

from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)

docs_split = text_splitter.split_documents(docs)
print(f"Total chunks: {len(docs_split)}")

from langchain.embeddings import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

from langchain.vectorstores import FAISS

# Create FAISS index
db = FAISS.from_documents(docs_split, embeddings)

query = "ASK YOUR QUERY?"
docs = db.similarity_search(query, k=2)

# Print top matching chunks
for i, doc in enumerate(docs):
    print(f"\nðŸ”¹ Match {i+1}:\n{doc.page_content}")
